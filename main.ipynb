{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    VotingClassifier,\n",
    "    BaggingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(os.path.join(\".\", 'alzheimers_disease_data.csv'))\n",
    "\n",
    "data = data.drop(columns=['DoctorInCharge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop(columns=['Diagnosis']))\n",
    "\n",
    "# Separate features and targets\n",
    "X = data.drop(columns=['PatientID', 'Diagnosis'])\n",
    "y = data['Diagnosis']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define individual base models\n",
    "cart = DecisionTreeClassifier(random_state=42)\n",
    "c45 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=True, eval_metric='logloss')\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Define additional models for stacking\n",
    "svc = SVC(probability=True, random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create ensemble methods\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf), ('gbm', gbm), ('ada', ada), ('xgb', xgb), ('lgbm', lgbm)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "bagging_clf = BaggingClassifier(estimator=rf, n_estimators=10, random_state=42)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('cart', cart),\n",
    "        ('svc', svc),\n",
    "        ('knn', knn),\n",
    "        ('rf', rf)\n",
    "    ],\n",
    "    final_estimator=logreg\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary of all models to evaluate\n",
    "models = {\n",
    "    'CART': cart,\n",
    "    'C4.5': c45,\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gbm,\n",
    "    'AdaBoost': ada,\n",
    "    'XGBoost': xgb,\n",
    "    'LightGBM': lgbm,\n",
    "    'Voting Ensemble': voting_clf,\n",
    "    'Bagging Ensemble': bagging_clf,\n",
    "    'Stacking Ensemble': stacking_clf\n",
    "}\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohammad-hossein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mohammad-hossein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 532, number of negative: 972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3282\n",
      "[LightGBM] [Info] Number of data points in the train set: 1504, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.353723 -> initscore=-0.602712\n",
      "[LightGBM] [Info] Start training from score -0.602712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohammad-hossein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mohammad-hossein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 532, number of negative: 972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3282\n",
      "[LightGBM] [Info] Number of data points in the train set: 1504, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.353723 -> initscore=-0.602712\n",
      "[LightGBM] [Info] Start training from score -0.602712\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'Precision': precision,\n",
    "            'F1 Score': f1,\n",
    "            'Classification Report': classification_rep\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed. Results saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save results to JSON and Excel files\n",
    "results_df = pd.DataFrame(results)\n",
    "results_json_path = os.path.join(\n",
    "    \".\", \"ensemble_model_results.json\")\n",
    "results_excel_path = os.path.join(\n",
    "    \".\", \"ensemble_comparison_results.xlsx\")\n",
    "\n",
    "os.makedirs(os.path.dirname(results_json_path), exist_ok=True)\n",
    "results_df.to_json(results_json_path, orient='records', indent=4)\n",
    "results_df.to_excel(results_excel_path, index=False)\n",
    "\n",
    "print(\"Evaluation completed. Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
